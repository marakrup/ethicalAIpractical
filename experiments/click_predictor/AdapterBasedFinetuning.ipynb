{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8UuXP188tC8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install transformers accelerate\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "3GZBkdLyP8Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://mind201910small.blob.core.windows.net/release/MINDsmall_train.zip\n",
        "!unzip /content/MINDsmall_train.zip -d mind_small_train"
      ],
      "metadata": {
        "id": "BPwc7yWo_yEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_news = pd.read_csv(\"/content/mind_small_train/news.tsv\", sep='\\t', names=['News ID','Category', 'SubCategory', 'Title', 'Abstract','Url','Title Entities','Abstract Entites'])\n",
        "df_users = pd.read_csv(\"/content/mind_small_train/behaviors.tsv\", sep='\\t', names=['Impression ID','User ID', 'Time', 'History', 'Impressions'])\n",
        "\n",
        "#use only users with more thane 10 impressions in our training loop\n",
        "df_users = df_users.groupby(\"User ID\").filter(lambda x: len(x) >= 10)"
      ],
      "metadata": {
        "id": "6KxMvQy8_4pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "title_map = {}\n",
        "all_titles = []\n",
        "\n",
        "for index, row in tqdm (df_news.iterrows(), total=len(df_news.index)):\n",
        "  news_id = row['News ID']\n",
        "  title_map[news_id] = index\n",
        "  all_titles.append(row['Title'])\n",
        "\n",
        "user_map = {}\n",
        "user_counter = 0\n",
        "for user in df_users['User ID'].unique():\n",
        "  user_map[user] = user_counter\n",
        "  user_counter += 1\n",
        "\n",
        "def convert_user(x):\n",
        "  return user_map[x]\n",
        "\n",
        "df_users['User ID'] = df_users['User ID'].apply(convert_user)\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "df_all = pd.DataFrame(data={'text': all_titles})\n",
        "tokenized_all = Dataset.from_pandas(df_all)\n",
        "tokenized_all = tokenized_all.map(lambda examples: tokenizer(examples[\"text\"]), batched=True)"
      ],
      "metadata": {
        "id": "GLDi96pqc6Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "train_test_ratio = 0.05\n",
        "max_users_per_article = 512\n",
        "\n",
        "total_number_samples = len(df_news.index)\n",
        "number_test_samples = int(total_number_samples*train_test_ratio)\n",
        "number_train_samples = total_number_samples - number_test_samples\n",
        "\n",
        "test_samples_news_id = set(df_news[number_train_samples:]['News ID'].values)\n",
        "\n",
        "train_data = {'user' : [], 'positive' : [], 'negatives' : []}\n",
        "test_data = {'user' : [], 'news' : [], 'label' : []}\n",
        "\n",
        "similarity_mapping = {}\n",
        "\n",
        "counter = 0\n",
        "\n",
        "#some articles are clicked in one impression and (of course) not-clicked in another impression therefore we have to remove all \"not-clciked-events\" of previous clicked news\n",
        "user_clicked = {}\n",
        "for index, row in tqdm(df_users.iterrows(), total=len(df_users.index)):\n",
        "  user_id = row['User ID']\n",
        "  for item in row['Impressions'].split(\" \"):\n",
        "    if item.endswith(\"-1\"):\n",
        "      already_clicked = user_clicked.get(user_id, set())\n",
        "      already_clicked.add(item.replace(\"-1\",\"\"))\n",
        "      user_clicked[user_id] = already_clicked\n",
        "\n",
        "for index, row in tqdm(df_users.iterrows(), total=len(df_users.index)):\n",
        "  positive_samples = []\n",
        "  negative_samples = []\n",
        "\n",
        "  user_id = row['User ID']\n",
        "\n",
        "  already_clicked = user_clicked[user_id]\n",
        "\n",
        "  for item in row['Impressions'].split(\" \"):\n",
        "\n",
        "    if item.endswith(\"-1\"):\n",
        "      news_id = item.replace(\"-1\", \"\")\n",
        "      if news_id in test_samples_news_id:\n",
        "        test_data['user'].append(user_id)\n",
        "        test_data['news'].append(news_id)\n",
        "        test_data['label'].append(1)\n",
        "      else:\n",
        "        positive_samples.append(news_id)\n",
        "    if item.endswith(\"-0\"):\n",
        "      news_id = item.replace(\"-0\", \"\")\n",
        "      if news_id in already_clicked:\n",
        "        continue\n",
        "      if news_id in test_samples_news_id:\n",
        "        test_data['user'].append(user_id)\n",
        "        test_data['news'].append(news_id)\n",
        "        test_data['label'].append(0)\n",
        "      else:\n",
        "        negative_samples.append(news_id)\n",
        "\n",
        "  if len(positive_samples) > 0 and len(negative_samples):\n",
        "    counter += 1\n",
        "    for positive in positive_samples:\n",
        "      train_data['user'].append(user_id)\n",
        "      train_data['positive'].append(positive)\n",
        "      train_data['negatives'].append(negative_samples)\n",
        "\n",
        "      news_similarity = similarity_mapping.get(positive, {'positive_users': set(), 'negative_users': set()})\n",
        "      news_similarity['positive_users'].add(user_id)\n",
        "      similarity_mapping[positive] = news_similarity\n",
        "\n",
        "  for negative in negative_samples:\n",
        "    news_similarity = similarity_mapping.get(negative, {'positive_users': set(), 'negative_users': set()})\n",
        "    news_similarity['negative_users'].add(user_id)\n",
        "    similarity_mapping[negative] = news_similarity\n",
        "\n",
        "df_train = pd.DataFrame(data=train_data)\n",
        "df_test = pd.DataFrame(data=test_data)\n",
        "print(f\"Found: {counter} samples\")\n",
        "\n",
        "#balance test data\n",
        "df_test_positive = df_test[df_test['label'] == 1]\n",
        "df_test_negative = df_test[df_test['label'] == 0]\n",
        "max_length = min(len(df_test_positive.index), len(df_test_negative.index))\n",
        "df_test = pd.concat([df_test_positive.sample(n=max_length), df_test_negative.sample(n=max_length)])\n",
        "df_test.describe()"
      ],
      "metadata": {
        "id": "dV2NDidqtOyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user, positives, negatives\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "import torch\n",
        "\n",
        "class CustomDatasetTrain(Dataset):\n",
        "    def __init__(self, dataframe, title_map, tokenized, similarity_mapping):\n",
        "        self.data = []\n",
        "        self.tokenized = tokenized\n",
        "        for index, row in dataframe.iterrows():\n",
        "          contrastive_samples = similarity_mapping[row['positive']]\n",
        "          positive = title_map[row['positive']]\n",
        "          negatives = [title_map[item] for item in row['negatives']]\n",
        "          self.data.append({'user': row['user'], 'positive': positive, 'negatives': negatives, 'contrastive_positive': contrastive_samples['positive_users'], 'contrastive_negative': contrastive_samples['negative_users'] })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        k = 4\n",
        "        #negative sampling\n",
        "        negative_samples = random.choices(item['negatives'], k=k)\n",
        "        all_samples = negative_samples + [item['positive']]\n",
        "\n",
        "        random_permutation = np.random.permutation(k + 1)\n",
        "        all_samples = np.array(all_samples)[random_permutation]\n",
        "        label = np.where(random_permutation == 4)[0][0]\n",
        "\n",
        "        texts = self.tokenized[all_samples]\n",
        "\n",
        "        max_width = max(len(a) for a in texts['input_ids'])\n",
        "\n",
        "        pad_to_multiple_of = 8\n",
        "        max_width = (\n",
        "              (max_width + pad_to_multiple_of - 1)\n",
        "              // pad_to_multiple_of\n",
        "              * pad_to_multiple_of\n",
        "          )\n",
        "\n",
        "        for i in range(0, len(texts['input_ids'])):\n",
        "          texts['input_ids'][i] = texts['input_ids'][i] + [0] * (max_width - len(texts['input_ids'][i]))\n",
        "          texts['attention_mask'][i] = texts['attention_mask'][i] + [0]* (max_width - len(texts['attention_mask'][i]))\n",
        "\n",
        "\n",
        "        return {'users': torch.tensor(item['user']).int(), 'input_ids': torch.tensor(texts['input_ids']), 'attention_mask': torch.tensor(texts['attention_mask']), 'label': torch.tensor(label), 'positive_samples': torch.tensor(list(item['contrastive_positive'])).int(), 'negative_samples': torch.tensor(list(item['contrastive_negative'])).int()}\n",
        "\n",
        "class CustomDatasetTest(Dataset):\n",
        "    def __init__(self, dataframe, title_map, tokenized):\n",
        "        self.data = []\n",
        "        self.tokenized = tokenized\n",
        "        for index, row in dataframe.iterrows():\n",
        "          item = self.tokenized[title_map[row['news']]]\n",
        "          item['users'] = row['user']\n",
        "          item['label'] = row['label']\n",
        "          self.data.append(item)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return item\n",
        "\n",
        "dataset_train = CustomDatasetTrain(df_train, title_map, tokenized_all, similarity_mapping)\n",
        "dataset_test = CustomDatasetTest(df_test, title_map, tokenized_all)"
      ],
      "metadata": {
        "id": "lTO5umWHH7BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train\n",
        "\n",
        "The modified BERT model architecture adapted from https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py _(commit-hash: 3ce3385c47b4bf302ff85911fee194e483c8fa00)_\n",
        "\n",
        "The main architectural changes are:  \n",
        "  - added a user_embedding matrix (and corresponding projection matrix if necessary) to the BERT model\n",
        "  - we use the dot product of a learned \"sample_comparator\" vector to compute logits instead of a regular linear layer (as it performed better)\n",
        "  - the classifier is used to predict probabilities  based on the already mentioned logits\n",
        "  - the training task is done on logit-level and consists of a classification task. for each user we input k negative samples and 1 positive sample in random order and the model has to predict the position of the positive sample.\n",
        "  - additionally we added a contrastive-loss term to the loss function to pull similar user_embeddings and push non-similar user_embeddings in the embedding space\n",
        "  -to model different user behaviour, we use the user_embeddings as adapters according to Liu et al. (2022) https://arxiv.org/pdf/2205.05638.pdf.\n",
        "  Therefore we consider, each user as a distinct \"downstream-task\" to learn.\n",
        "  In comparison to Liu et al. we did use adapters only on the last transformer layer and dispensed with the intermediate layer adapter."
      ],
      "metadata": {
        "id": "AKB8nvc6TpGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertModel\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "import math\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss, BCELoss\n",
        "\n",
        "from transformers.modeling_outputs import (\n",
        "    SequenceClassifierOutput,\n",
        ")\n",
        "\n",
        "from transformers.models.bert.modeling_bert import (\n",
        "    BertIntermediate,\n",
        "    BertOutput,\n",
        "    BertAttention,\n",
        "    BertSelfOutput,\n",
        "    BertSelfAttention,\n",
        "    BertLayer,\n",
        "    apply_chunking_to_forward\n",
        ")\n",
        "\n",
        "class BertForSequenceClassificationAdapters(BertForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        classifier_dropout = (\n",
        "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.dropout = nn.Dropout(classifier_dropout)\n",
        "        self.classifier = nn.Linear(1, config.num_labels)\n",
        "\n",
        "        self.adapter_size = config.hidden_size * 2# + config.intermediate_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "\n",
        "        self.user_embeddings = nn.Embedding(config.num_users, self.embedding_size)\n",
        "        #add additional projection layer if adapter_size != self.embedding_size\n",
        "        if self.adapter_size != self.embedding_size:\n",
        "          self.user_projection = nn.Linear(self.embedding_size, self.adapter_size)\n",
        "        self.user_dropout = torch.nn.Dropout(config.user_dropout_prob)\n",
        "        self.user_norm = torch.nn.LayerNorm(self.embedding_size, eps=config.layer_norm_eps)\n",
        "        self.adapter_layer = BertLayerAdapters(config)\n",
        "\n",
        "        self.sample_comparators = torch.nn.parameter.Parameter(data=torch.zeros(config.num_classification_heads,config.hidden_size), requires_grad=True)\n",
        "        self.sample_comparators.data.normal_(mean=0.0, std=config.initializer_range)\n",
        "        self.sample_norm = torch.nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "\n",
        "        self.register_buffer(\"adapter_bias\", torch.ones(1, self.adapter_size))\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def calculate_contrastive_loss(self, current_user, positive_indices, negative_indices, margin: float = 0.5):\n",
        "        \"\"\"\n",
        "        Computes Contrastive Loss\n",
        "        \"\"\"\n",
        "\n",
        "        positive_samples = torch.cartesian_prod(current_user, positive_indices.squeeze(dim=0))\n",
        "        negative_samples = torch.cartesian_prod(current_user, negative_indices.squeeze(dim=0))\n",
        "\n",
        "\n",
        "        #similar labesl are zeros / disimilar labels are ones\n",
        "        positive_samples_labels = torch.zeros(negative_samples.shape[0], device=negative_samples.device)\n",
        "        negative_samples_labels = torch.ones(positive_samples.shape[0], device=positive_samples.device)\n",
        "\n",
        "        all_contrastive_samples = torch.concat([positive_samples, negative_samples],dim=0)\n",
        "        label  = torch.concat([positive_samples_labels, negative_samples_labels],dim=0)\n",
        "\n",
        "        x1 = self.user_embeddings(all_contrastive_samples[:,0])\n",
        "        x2 = self.user_embeddings(all_contrastive_samples[:,1])\n",
        "\n",
        "        x1 = torch.nn.functional.normalize(x1, p=2, dim=-1)\n",
        "        x2 = torch.nn.functional.normalize(x2, p=2, dim=-1)\n",
        "\n",
        "        dist = torch.nn.functional.pairwise_distance(x1, x2)\n",
        "\n",
        "        loss = (1 - label) * torch.pow(dist, 2) + (label) * torch.pow(torch.clamp(margin - dist, min=0.0), 2)\n",
        "        loss = torch.mean(loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        users: Optional[torch.Tensor] = None,\n",
        "        positive_samples: Optional[torch.Tensor] = None,\n",
        "        negative_samples: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if len(input_ids.shape) > 2:\n",
        "          input_ids = input_ids.squeeze(dim=0)\n",
        "          attention_mask = attention_mask.squeeze(dim=0)\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        unpooled_output = outputs[0]\n",
        "\n",
        "        adapter_values = self.adapter_bias\n",
        "\n",
        "        if users is not None:\n",
        "          users = users.squeeze(dim=0)\n",
        "          user_embeds = self.user_embeddings(users)\n",
        "          user_embeds = self.user_norm(user_embeds)\n",
        "          user_embeds = self.user_dropout(user_embeds)\n",
        "          if self.adapter_size != self.embedding_size:\n",
        "            adapter_values = self.adapter_bias + self.user_projection(user_embeds)\n",
        "          else:\n",
        "            adapter_values = self.adapter_bias + user_embeds\n",
        "\n",
        "        extended_mask = self.bert.get_extended_attention_mask(attention_mask, input_ids.size())\n",
        "\n",
        "        unpooled_output = self.adapter_layer(\n",
        "            unpooled_output,\n",
        "            extended_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            user_embeds=adapter_values.unsqueeze(dim=1),\n",
        "        )\n",
        "\n",
        "        if outputs.hidden_states is not None:\n",
        "          outputs.hidden_states = outputs.hidden_states + (unpooled_output[0],)\n",
        "        if outputs.attentions is not None:\n",
        "          outputs.attentions = outputs.attentions + (unpooled_output[1],)\n",
        "\n",
        "        pooled_output = self.bert.pooler(unpooled_output[0])\n",
        "\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "\n",
        "        samples = self.sample_norm(self.sample_comparators)\n",
        "        samples = self.dropout(samples)\n",
        "\n",
        "        logits = torch.inner(pooled_output, samples)\n",
        "\n",
        "        click_prediction = self.classifier(logits.detach())\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                if input_ids.shape[0] > 1:\n",
        "                  loss = loss_fct(logits.view(-1, 5), labels)\n",
        "\n",
        "                  click_prediction_labels = torch.zeros(5, dtype=torch.long, device=click_prediction.device)\n",
        "                  click_prediction_labels[labels] = torch.tensor(1, device=click_prediction.device)\n",
        "\n",
        "                  loss_fct = CrossEntropyLoss(weight=torch.tensor([0.25,1.], device=click_prediction.device))\n",
        "                  loss += loss_fct(click_prediction.view(-1, 2), click_prediction_labels)\n",
        "                else:\n",
        "                  loss = loss_fct(click_prediction.view(-1, 2), labels)\n",
        "\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = BCEWithLogitsLoss()\n",
        "                loss = loss_fct(logits, labels)\n",
        "\n",
        "\n",
        "            if positive_samples is not None and negative_samples is not None and users is not None:\n",
        "              contrastive_loss = self.calculate_contrastive_loss(users.unsqueeze(dim=0), positive_samples.squeeze(dim=0), negative_samples.squeeze(dim=0))\n",
        "              loss += contrastive_loss\n",
        "\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=click_prediction,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "class BertLayerAdapters(BertLayer):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
        "        self.seq_len_dim = 1\n",
        "        self.attention = BertAttentionAdapters(config)\n",
        "        self.is_decoder = config.is_decoder\n",
        "        self.add_cross_attention = config.add_cross_attention\n",
        "        if self.add_cross_attention:\n",
        "            if not self.is_decoder:\n",
        "                raise ValueError(f\"{self} should be used as a decoder model if cross attention is added\")\n",
        "            self.crossattention = BertAttention(config, position_embedding_type=\"absolute\")\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "        self.output = BertOutput(config)\n",
        "        self.config = config\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        user_embeds: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "\n",
        "        #added\n",
        "        multiply_keys = user_embeds[:,:,:self.config.hidden_size]\n",
        "        multiply_values = user_embeds[:,:,self.config.hidden_size:self.config.hidden_size*2]\n",
        "        multiply_intermediate = None#user_embeds[:,:,self.config.hidden_size*2:]\n",
        "\n",
        "        self_attention_outputs = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            past_key_value=self_attn_past_key_value,\n",
        "            multiply_keys=multiply_keys,\n",
        "            multiply_values=multiply_values\n",
        "        )\n",
        "        attention_output = self_attention_outputs[0]\n",
        "\n",
        "        # if decoder, the last output is tuple of self-attn cache\n",
        "        if self.is_decoder:\n",
        "            outputs = self_attention_outputs[1:-1]\n",
        "            present_key_value = self_attention_outputs[-1]\n",
        "        else:\n",
        "            outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
        "\n",
        "        cross_attn_present_key_value = None\n",
        "        if self.is_decoder and encoder_hidden_states is not None:\n",
        "            if not hasattr(self, \"crossattention\"):\n",
        "                raise ValueError(\n",
        "                    f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers\"\n",
        "                    \" by setting `config.add_cross_attention=True`\"\n",
        "                )\n",
        "\n",
        "            # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n",
        "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
        "            cross_attention_outputs = self.crossattention(\n",
        "                attention_output,\n",
        "                attention_mask,\n",
        "                head_mask,\n",
        "                encoder_hidden_states,\n",
        "                encoder_attention_mask,\n",
        "                cross_attn_past_key_value,\n",
        "                output_attentions,\n",
        "            )\n",
        "            attention_output = cross_attention_outputs[0]\n",
        "            outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n",
        "\n",
        "            # add cross-attn cache to positions 3,4 of present_key_value tuple\n",
        "            cross_attn_present_key_value = cross_attention_outputs[-1]\n",
        "            present_key_value = present_key_value + cross_attn_present_key_value\n",
        "\n",
        "        layer_output = apply_chunking_to_forward(\n",
        "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, (attention_output, multiply_intermediate)\n",
        "        )\n",
        "        outputs = (layer_output,) + outputs\n",
        "\n",
        "        # if decoder, return the attn key/values as the last output\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (present_key_value,)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def feed_forward_chunk(self, attention_output):\n",
        "        attention_output, multiply_intermediate = attention_output\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        #intermediate_output = intermediate_output * multiply_intermediate #added\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        return layer_output\n",
        "\n",
        "class BertAttentionAdapters(BertAttention):\n",
        "    def __init__(self, config, position_embedding_type=None):\n",
        "        super().__init__(config, position_embedding_type)\n",
        "        self.self = BertSelfAttentionAdapters(config, position_embedding_type=position_embedding_type)\n",
        "        self.output = BertSelfOutput(config)\n",
        "        self.pruned_heads = set()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        multiply_keys: Optional[torch.FloatTensor] = None,\n",
        "        multiply_values: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        self_outputs = self.self(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            head_mask,\n",
        "            encoder_hidden_states,\n",
        "            encoder_attention_mask,\n",
        "            multiply_keys,\n",
        "            multiply_values,\n",
        "            past_key_value,\n",
        "            output_attentions,\n",
        "        )\n",
        "        attention_output = self.output(self_outputs[0], hidden_states)\n",
        "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
        "        return outputs\n",
        "\n",
        "class BertSelfAttentionAdapters(BertSelfAttention):\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.FloatTensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        multiply_keys: Optional[torch.FloatTensor] = None,\n",
        "        multiply_values: Optional[torch.FloatTensor] = None,\n",
        "        past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.Tensor]:\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "\n",
        "        # If this is instantiated as a cross-attention module, the keys\n",
        "        # and values come from an encoder; the attention mask needs to be\n",
        "        # such that the encoder's padding tokens are not attended to.\n",
        "        is_cross_attention = encoder_hidden_states is not None\n",
        "\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_layer = past_key_value[0]\n",
        "            value_layer = past_key_value[1]\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif is_cross_attention:\n",
        "            key_layer = self.transpose_for_scores(self.key(encoder_hidden_states) * multiply_keys)\n",
        "            value_layer = self.transpose_for_scores(self.value(encoder_hidden_states) * multiply_values)\n",
        "            attention_mask = encoder_attention_mask\n",
        "        elif past_key_value is not None:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states) * multiply_keys)\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states) * multiply_values)\n",
        "            key_layer = torch.cat([past_key_value[0], key_layer], dim=2)\n",
        "            value_layer = torch.cat([past_key_value[1], value_layer], dim=2)\n",
        "        else:\n",
        "            key_layer = self.transpose_for_scores(self.key(hidden_states) * multiply_keys)\n",
        "            value_layer = self.transpose_for_scores(self.value(hidden_states) * multiply_values)\n",
        "\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "\n",
        "        use_cache = past_key_value is not None\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_layer, value_layer)\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "\n",
        "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
        "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
        "            if use_cache:\n",
        "                position_ids_l = torch.tensor(key_length - 1, dtype=torch.long, device=hidden_states.device).view(\n",
        "                    -1, 1\n",
        "                )\n",
        "            else:\n",
        "                position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
        "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
        "            distance = position_ids_l - position_ids_r\n",
        "\n",
        "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
        "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
        "\n",
        "            if self.position_embedding_type == \"relative_key\":\n",
        "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores\n",
        "            elif self.position_embedding_type == \"relative_key_query\":\n",
        "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
        "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
        "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
        "\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
        "        if attention_mask is not None:\n",
        "            attention_scores = attention_scores + attention_mask\n",
        "\n",
        "\n",
        "\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Mask heads if we want to\n",
        "        if head_mask is not None:\n",
        "            attention_probs = attention_probs * head_mask\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "\n",
        "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            outputs = outputs + (past_key_value,)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "from transformers.configuration_utils import PretrainedConfig\n",
        "\n",
        "class BertConfigAdapters(PretrainedConfig):\n",
        "    model_type = \"bert\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=30522,\n",
        "        hidden_size=768,\n",
        "        num_hidden_layers=12,\n",
        "        num_attention_heads=12,\n",
        "        intermediate_size=3072,\n",
        "        hidden_act=\"gelu\",\n",
        "        hidden_dropout_prob=0.1,\n",
        "        attention_probs_dropout_prob=0.1,\n",
        "        max_position_embeddings=512,\n",
        "        type_vocab_size=2,\n",
        "        initializer_range=0.02,\n",
        "        layer_norm_eps=1e-12,\n",
        "        pad_token_id=0,\n",
        "        position_embedding_type=\"absolute\",\n",
        "        use_cache=True,\n",
        "        classifier_dropout=None,\n",
        "        num_classification_heads=2,\n",
        "        embedding_size=32,\n",
        "        num_users = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(pad_token_id=pad_token_id, **kwargs)\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.hidden_act = hidden_act\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.hidden_dropout_prob = hidden_dropout_prob\n",
        "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.type_vocab_size = type_vocab_size\n",
        "        self.initializer_range = initializer_range\n",
        "        self.layer_norm_eps = layer_norm_eps\n",
        "        self.position_embedding_type = position_embedding_type\n",
        "        self.use_cache = use_cache\n",
        "        self.classifier_dropout = classifier_dropout\n",
        "        self.num_classification_heads = num_classification_heads\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_users = num_users"
      ],
      "metadata": {
        "id": "O7OicDRuuLtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define evaluation metrics (accuracy and AreaUnderCurve)\n",
        "import evaluate\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    accumulated_labels = []\n",
        "    accumulated_predictions = []\n",
        "\n",
        "    for i in range(0, len(labels)):\n",
        "      padding = labels[i] == -100\n",
        "      accumulated_labels.extend(labels[i][~padding])\n",
        "      accumulated_predictions.extend(predictions[i][~padding])\n",
        "\n",
        "    labels = np.array(accumulated_labels)\n",
        "    logits = np.array(accumulated_predictions)\n",
        "\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "\n",
        "    accuracy_value = accuracy.compute(predictions=predictions, references=labels)\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).squeeze().numpy()\n",
        "\n",
        "    multi_class_labels = np.zeros_like(probs)\n",
        "    multi_class_labels[labels == 0] = [1,0]\n",
        "    multi_class_labels[labels == 1] = [0,1]\n",
        "    roc_auc_value = roc_auc_score(multi_class_labels, probs)\n",
        "    accuracy_value['auc'] = roc_auc_value\n",
        "    accuracy_value['mean_prediction'] = np.mean(predictions)\n",
        "    accuracy_value['mean_labels'] = np.mean(labels)\n",
        "\n",
        "    return accuracy_value"
      ],
      "metadata": {
        "id": "EVcDrHloTmuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the pre-trained language model into our architecture and prepare for training\n",
        "\n",
        "from transformers import AutoConfig\n",
        "\n",
        "config = AutoConfig.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "config.num_users = user_counter\n",
        "config.embedding_size = 128\n",
        "config.num_classification_heads = 1\n",
        "config.user_dropout_prob = 0.3\n",
        "\n",
        "model = BertForSequenceClassificationAdapters.from_pretrained('sentence-transformers/all-MiniLM-L6-v2', config=config)\n",
        "#copy last layer\n",
        "last_layer = model.bert.encoder.layer[-1]\n",
        "model.adapter_layer.load_state_dict(last_layer.state_dict())\n",
        "#remove duplicated last layer\n",
        "model.bert.encoder.layer = model.bert.encoder.layer[:-1]\n",
        "model.config.num_hidden_layers = len(model.bert.encoder.layer)\n",
        "\n",
        "#Freeze all weights\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "#Unfreeze LayerNorm weights to avoid overfitting\n",
        "for module in model.modules():\n",
        "  if isinstance(module, torch.nn.LayerNorm):\n",
        "    for param in module.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "#Unfreeze user embeddings\n",
        "for param in model.user_embeddings.parameters():\n",
        "  param.requires_grad = True\n",
        "for param in model.user_projection.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "#Unfreeze classifier weights\n",
        "for param in model.classifier.parameters():\n",
        "  param.requires_grad = True\n",
        "model.sample_comparators.requires_grad = True"
      ],
      "metadata": {
        "id": "QaJlTvvR1_sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train all users' classifiers\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=5,\n",
        "    learning_rate = 1e-3,\n",
        "    warmup_ratio=0.05,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    weight_decay = 0.1,\n",
        "    save_strategy='no',\n",
        "    optim='adamw_torch',\n",
        "    gradient_accumulation_steps=4,\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "7LAcXDn6TyTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fine-tune only on user_embeddings\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "#Freeze all weights\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in model.user_norm.parameters():\n",
        "  param.requires_grad = True\n",
        "for param in model.adapter_layer.output.LayerNorm.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "\n",
        "#Unfreeze user embeddings\n",
        "for param in model.user_embeddings.parameters():\n",
        "  param.requires_grad = True\n",
        "for param in model.user_projection.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=20,\n",
        "    learning_rate = 1e-3,\n",
        "    warmup_ratio=0.05,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    weight_decay = 0.1,\n",
        "    save_strategy='no',\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Vs_hcv_txLDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save results to huggingface and shut down notebook automatically"
      ],
      "metadata": {
        "id": "CPh5ODt0waM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "OnhnoIr4QPm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save all relevant files\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "import json\n",
        "\n",
        "model_name = \"josh-oo/news-classifier\"\n",
        "commit_message = \"First full upload\"\n",
        "\n",
        "#upload model\n",
        "model.push_to_hub(model_name, commit_message=commit_message)\n",
        "#upload tokenizer\n",
        "tokenizer.push_to_hub(model_name, commit_message=commit_message)\n",
        "\n",
        "#upload correspoding user_mappings\n",
        "with open('user_mapping.json', 'w') as fp:\n",
        "    json.dump(user_map, fp)\n",
        "\n",
        "api = HfApi()\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"user_mapping.json\",\n",
        "    path_in_repo=\"user_mapping.json\",\n",
        "    repo_id=model_name,\n",
        "    repo_type=\"model\",\n",
        ")"
      ],
      "metadata": {
        "id": "gKLUgV86QrRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "D-4VTIAA3H5J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}