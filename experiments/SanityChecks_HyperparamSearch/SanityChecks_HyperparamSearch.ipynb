{"cells":[{"cell_type":"markdown","source":["# Dimensionality Reduction & Clustering\n","In this notebook you can find all experiments used for dimensionality reduction and clustering, including part of the sanity checks mentioned in the report and the UMAP hyperparameter search.\n","\n","Please note that this notebook has been designed to be used in a google colab setup, as the UMAP iterations used for the hyperparemter search are computationally expensive. All colab-specific code sections have been highlighted as such.\n","\n","We recommend to import the entire SanityChecks_HyperparamSearch-Folder into your colab drive to ensure a seamless working of this notebook. In order to be able to use the defined path structure for embedding retrieval and plot storage the folder shall be placed directly in the drive and not within a subfolder."],"metadata":{"id":"YNzJ8fgSqQ7X"}},{"cell_type":"markdown","metadata":{"id":"2mJ7qTWjEwz-"},"source":["# 0. Setup\n","We will begin by importing all required libraries and fixing the plotting setup."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DkBd8fm6ffZp"},"outputs":[],"source":["#imports\n","import pandas as pd\n","import numpy as np\n","import pickle\n","from sklearn.datasets import load_digits\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","from mpl_toolkits import mplot3d\n","import matplotlib.colors as mcolors\n","import seaborn as sns\n","import random\n","import os\n","from sklearn.cluster import KMeans\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.cluster import SpectralClustering\n","from sklearn.cluster import Birch\n","from sklearn.cluster import OPTICS\n","from sklearn.cluster import DBSCAN\n","from sklearn.decomposition import PCA\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn import mixture\n","from sklearn.mixture import BayesianGaussianMixture\n","from scipy.spatial.distance import pdist, squareform\n","from scipy.spatial import distance\n","#colab specific: ######################################################################\n","!pip install umap-learn[plot]\n","!pip install holoviews\n","!pip install -U ipykernel\n","#######################################################################################\n","import umap"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xkMplxyBfmpW","executionInfo":{"status":"ok","timestamp":1691947377814,"user_tz":-120,"elapsed":7,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}}},"outputs":[],"source":["#plot settings\n","%matplotlib inline\n","sns.set(style='white', context='notebook', rc={'figure.figsize':(3,3)})\n","plt.ioff() #ensures that no plots are shown within the notebook if not explicity demanded by plt.show()\n","\n","#color configuration\n","colors = list(mcolors.CSS4_COLORS.keys())\n","colors = random.sample(colors, 100)\n","colors = np.array(colors)"]},{"cell_type":"markdown","metadata":{"id":"17PgBa48FzAE"},"source":["# 1. Setting the Parameters\n","For a better legibility of this document, we will store all parameter settings in this section."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"64sjjIDGGB-7","executionInfo":{"status":"ok","timestamp":1691947380381,"user_tz":-120,"elapsed":275,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}}},"outputs":[],"source":["#colab specific path setup for plot storage: #######################################################\n","#Path to colab workspace\n","w_path = '/content/gdrive/MyDrive/SanityChecks_HyperparamSearch/'\n","####################################################################################################\n","\n","#Pre-processing of the imported data - choose between...\n","# 'feature_stand': feature standardization leading to unit vairance and zero mean of all features across the samples\n","# 'norm_vecs': Normalized embedding vectors, that project all embedding vectors on a unit sphere\n","# 'none'\n","pre_processing = 'none'\n","\n","\n","#Dimensionality reduction of the imported data - choose between...\n","# 'PCA'\n","# 'UMAP'\n","dim_reduction = 'UMAP'\n","\n","\n","#Data-generation network (parameter is useful in case several sets of embeddings have been used which have been trained using different network architectures)\n","data_generation = 'final'"]},{"cell_type":"markdown","metadata":{"id":"DqGMqlpOH0Qr"},"source":["# 2. Loading the embeddings\n","\n","Now, we will have to load the user embeddings from the npy file they are stored in.\n","\n","We also want to check that the imported data has the desired dimensions, to make sure that nothing went wrong throughout the process of creating and storing the embeddings in the npy file, and importing them into this document."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4866,"status":"ok","timestamp":1691947880830,"user":{"displayName":"Mara K.","userId":"07948848994085884880"},"user_tz":-120},"id":"k0MtN7iqH5U_","outputId":"4e7055cd-2fe7-4ede-d9ff-dd664bb8fee1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","(2062, 384)\n"]}],"source":["#colab specific import setup: ######################################################################\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","####################################################################################################\n","\n","#colab specific path setup for plot storage: #######################################################\n","#importing the high-dimensional user embeddings retrieved from the model pre-training\n","path= w_path + 'user_embeddings_final.npy'\n","####################################################################################################\n","\n","#loading the data\n","data = np.load(path)\n","\n","#creating folder to sort images into\n","hyperparam_path = w_path + 'hyperparameter_search'\n","if os.path.exists(hyperparam_path) == False:\n","  os.mkdir(hyperparam_path)\n","data_gen_path = hyperparam_path + '/' + data_generation\n","if os.path.exists(data_gen_path) == False:\n","  os.mkdir(data_gen_path)\n","\n","#Check that embeddings have the correct shape\n","print(data.shape)"]},{"cell_type":"markdown","metadata":{"id":"1pvdqu4vI9Sn"},"source":["# 3. Pre-processing the embeddings\n","Before passing our user embeddings on to the dimensionality reduction, we will have to pre-process them, to make sure that not a few features only dominate the dimensionality reduction due to scale differences."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"iWfpfxuJfwA0","executionInfo":{"status":"ok","timestamp":1691947887318,"user_tz":-120,"elapsed":249,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}}},"outputs":[],"source":["#checking which means of data pre-processing to use\n","#   norm_vecs     = embedding normalization\n","#   feature_stand = feature standardization\n","#   none          = no pre-processing\n","if pre_processing == 'norm_vecs':\n","  scale_factors = np.sum(data, axis = 1)\n","  scale_factors = scale_factors[:, np.newaxis]\n","  processed_data = data / scale_factors\n","elif pre_processing =='feature_stand':\n","  processed_data = StandardScaler().fit_transform(data)\n","else:\n","  processed_data = data\n","\n","#create folder to sort images into\n","pre_processing_path = data_gen_path + '/' + pre_processing\n","if os.path.exists(pre_processing_path) == False:\n","  os.mkdir(pre_processing_path)\n"]},{"cell_type":"markdown","metadata":{"id":"92wlMVhTK-I7"},"source":["# 4. Performing Dimensionality Reduction\n","In this section we perform hyperparameter search for dimensionality reduction. Dimensionality reduction can be performed using either UMAP or PCA. Please see section 1 in order to configer the transformation used.\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"0qSyZBX8dojj","executionInfo":{"status":"ok","timestamp":1691947889946,"user_tz":-120,"elapsed":248,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}}},"outputs":[],"source":["#initializing dict to save reduced dimensionality embeddings in, and to later retrieve those embeddings based on the parameters\n","embeddings = {}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLu151ClQsaw"},"outputs":[],"source":["#Create folders to later deposit images in\n","path_dimred = pre_processing_path\n","if os.path.exists(path_dimred) == False:\n","  os.mkdir(path_dimred)\n","\n","path2D = path_dimred + '/' + 'output_dim_2'\n","if os.path.exists(path2D) == False:\n","  os.mkdir(path2D)\n","\n","path3D = path_dimred + '/' + 'output_dim_3'\n","if os.path.exists(path3D) == False:\n","  os.mkdir(path3D)\n","\n","#Checking which means of dimensionality reduction to use\n","if dim_reduction == 'UMAP':\n","\n","  #UMAP\n","  #iterating over plausible hyperparameter values: output dimensionality, number of neighbors, minimum distance and distance metric\n","  #note that output dimensionality is not an actual hyperparameter; we only use two dimensions as this helps for visual inspections of the results\n","  for n_dims in [2,3]:\n","    for n_neighbors in np.concatenate((range(2,11,1), range(15,51,5))): #n_neighbors in steps of 1 from 2-10 and in steps of 5 from 15 to 50\n","      for min_dist in range(0,10,1): #min_dist between 0 and 1 in steps of 0.1\n","        for measure in ['euclidean','manhattan','cosine']: #different distance measures\n","\n","          reducer = umap.UMAP(n_components = n_dims, n_neighbors = n_neighbors, min_dist = min_dist/10, metric = measure) #initialize umap with desired hyperparams\n","          reduced_data = reducer.fit_transform(processed_data)#calculate umap and return reduced embeddings\n","          embeddings[data_generation+ pre_processing + dim_reduction + str(n_dims) + str(n_neighbors)+ str(min_dist/10) + measure] = reduced_data #saving embeddings for retrieval during clustering\n","\n","          #two-dimensional case\n","          if n_dims == 2:\n","            #plotting result and saving plots as images\n","            plt.figure()\n","            plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=0.1)\n","            plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + str(n_neighbors)+ '     min_dist:' + str(min_dist/10) + '     metric:' + measure, fontsize=8)\n","            path2D_image = path2D + '/' + str(n_neighbors) + '_' + str(min_dist/10) + '_' + measure +'.pdf'\n","            plt.savefig(path2D_image, pad_inches = 15)\n","\n","          #three-dimensional case\n","          else:\n","            #plotting result and saving plots as images\n","            plt.figure()\n","            ax = plt.axes(projection='3d')\n","            ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2],s=0.1)\n","            plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + str(n_neighbors)+ '     min_dist:' + str(min_dist/10) + '     metric:' + measure, fontsize=8)\n","            path3D_image = path3D + '/' + str(n_neighbors) + '_' + str(min_dist/10) + '_' + measure +'.pdf'\n","            plt.savefig(path3D_image, pad_inches = 15)\n","\n","    if os.path.exists(data_gen_path +'/' + 'reduced_embeddings') == False:\n","      os.mkdir(data_gen_path +'/' +  'reduced_embeddings')\n","\n","    with open(data_gen_path + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_UMAP_' + pre_processing + '_' + str(n_dims) + '.pickle', 'wb') as file:\n","      pickle.dump(embeddings, file)\n","\n","\n","else:\n","  #PCA\n","  #iterating over hyperparameter: output dimensionality\n","  for n_dims in [2,3]:\n","    pca = PCA(n_components = n_dims)\n","    reduced_data = pca.fit_transform(processed_data)\n","    embeddings[data_generation+ pre_processing + dim_reduction + str(n_dims) + 'na'+ 'na' + 'na'] = reduced_data #saving embeddings for retrieval during clustering\n","\n","    #two-dimensional case\n","    if n_dims == 2:\n","      #plotting result and saving plots as images\n","      plt.figure()\n","      plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction, fontsize=8)\n","      path2D_image = path2D + '/'+ 'PCA' + '.pdf'\n","      plt.savefig(path2D_image, pad_inches = 15)\n","\n","    #three-dimensional case\n","    else:\n","      #plotting result and saving plots as images\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2],s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction, fontsize=8)\n","      path3D_image = path3D + '/' + 'PCA' +'.pdf'\n","      plt.savefig(path3D_image, pad_inches = 15)\n","\n","    with open(data_gen_path + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_PCA_' + pre_processing + '.pickle', 'wb') as file:\n","      pickle.dump(embeddings, file)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Hl1ZDb53R0S-"},"source":["# 5. Selecting suitable reduced embeddings\n","As a next step, we will have to visually inspect the resulting plots to determine the most suitable reduced dimensionality embeddings. We will note down the hyperparamters used to create these embeddings.\n","\n","The chosen embeddings can be retrieved later when clustering by listing the hyperparameters used to create them as a keyword for the \"*embeddings*\" dictionary."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ct7P_7WgWVg"},"outputs":[],"source":["#extracting the saved embeddings from our files\n","\n","umap_feature_stand2 = {}\n","umap_feature_stand3 = {}\n","umap_norm_vecs2 = {}\n","umap_norm_vecs3 = {}\n","umap_none2 = {}\n","umap_none3 = {}\n","pca = {}\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_UMAP_none_2.pickle', 'rb') as file:\n","    umap_none2 = pickle.load(file)\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_UMAP_none_3.pickle', 'rb') as file:\n","    umap_none3 = pickle.load(file)\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_UMAP_feature_stand_2.pickle', 'rb') as file:\n","    umap_feature_stand2 = pickle.load(file)\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_UMAP_feature_stand_3.pickle', 'rb') as file:\n","    umap_feature_stand3 = pickle.load(file)\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_UMAP_norm_vecs_2.pickle', 'rb') as file:\n","    umap_norm_vex2 = pickle.load(file)\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_UMAP_norm_vecs_3.pickle', 'rb') as file:\n","    umap_norm_vex3 = pickle.load(file)\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_PCA_feature stand.pickle', 'rb') as file:\n","    pca_feature_stand = pickle.load(file)\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_PCA_norm_vecs.pickle', 'rb') as file:\n","    pca_norm_vecs = pickle.load(file)\n","\n","with open(w_path + data_generation + '/' + 'reduced_embeddings'+ '/' + 'red_embeddings_PCA_none.pickle', 'rb') as file:\n","    pca_none = pickle.load(file)\n","\n","\n","#Merging the saved embeddings into one dictionary\n","embeddings = umap_none2 | umap_none3 | umap_feature_stand2 | umap_feature_stand3 | umap_norm_vex2 | umap_norm_vex3 | pca_feature_stand | pca_norm_vecs | pca_none\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ZQk4bm5drOe"},"outputs":[],"source":["#selecting best values from previous dimensionality reduction and placing them in iterable array\n","\n","########## in case there's just one hyperparameter configuration ################################\n","data_gen_array = [data_generation, data_generation]\n","pre_proc_array = ['none', 'none']\n","dim_red_array = ['UMAP', 'UMAP']\n","n_dims_array = ['2','3']\n","neighbors_array = ['2','2']\n","dist_array = ['0.4', '0.4']\n","metric_array = ['cosine', 'cosine']\n","iter_array = np.column_stack((data_gen_array, pre_proc_array, dim_red_array, n_dims_array, neighbors_array, dist_array, metric_array))\n","##################################################################################################\n","\n","\n","\n","########## in case of many hyperparameter configurations ########################################\n","#data_gen_array = np.full((34,), data_generation)\n","\n","#pre_proc_array_1 = np.full((21,), 'feature_stand')\n","#pre_proc_array_2 = np.full((13,), 'norm_vecs')\n","#pre_proc_array = np.concatenate((pre_proc_array_1, pre_proc_array_2))\n","\n","\n","#dim_red_array = np.full((34,),'UMAP')\n","\n","#n_dims_array_1 = np.full((10,),'2')\n","#n_dims_array_2 = np.full((11,), '3')\n","#n_dims_array_3 = np.full((7,),'2')\n","#n_dims_array_4 = np.full((6,), '3')\n","#n_dims_array = np.concatenate((n_dims_array_1, n_dims_array_2, n_dims_array_3, n_dims_array_4))\n","\n","#neighbors_array = np.full((34,), '2')\n","\n","#dist_array = ['0.4', '0.3', '0.6', '0.3', '0.7', '0.9', '0.3', '0.7', '0.5', '0.4', '0.4', '0.3', '0.6', '0.5', '0.6', '0.5', '0.6', '0.7','0.7','0.8','0.5','0.4','0.4','0.6','0.8','0.9','0.5','0.7','0.1', '0.2', '0.5', '0.6', '0.4','0.3']\n","\n","#metric_array = ['cosine','cosine','cosine','euclidean','euclidean','euclidean','euclidean','manhattan','euclidean','euclidean','cosine','cosine','cosine','cosine','euclidean','manhattan','manhattan','euclidean','manhattan','euclidean','euclidean','euclidean','manhattan','euclidean','euclidean','euclidean','manhattan','euclidean','euclidean','manhattan','manhattan','manhattan','manhattan','euclidean']\n","\n","#iter_array = np.column_stack((data_gen_array, pre_proc_array, dim_red_array, n_dims_array, neighbors_array, dist_array, metric_array))\n","###################################################################################################"]},{"cell_type":"markdown","metadata":{"id":"nl49ibMnMGjs"},"source":["##6 Sanity Check: Proximity Preservation\n","In this section, we want to see if the proximity of two points in the higher-dimensional embedding is preserved in the lower-dimensional embedding.\n","\n","In order to do this, we will perform three checks:\n","\n","**Check 1:** Does the single nearest neighbor of a point in the high-dimensional embedding lie within the same cluster as this point in the low-dimensional embedding?\n","\n","**Check 2:** Do the 20 nearest neighbors of a point in the high-dimensional embedding lie within the same cluster as this point in the low-dimensional embedding?\n","\n","**Check 3**: Does a large group of nearest neighbors of a point in the high-dimensinoal embedding lie within the same cluster as this point in the low-dimensional embedding?\n","\n","**Check 4:** Does a point that is not in close proximity of another point in the high-dimensional embedding lie in a different cluster than this point in the low-dimensional embedding?"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"jD713RzD5h4o","executionInfo":{"status":"ok","timestamp":1691948035843,"user_tz":-120,"elapsed":263,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}}},"outputs":[],"source":["#Prepare folders to store resulting plots in\n","\n","sanity_check_path = w_path + 'UMAP_sanity_checks'\n","check_1_path = sanity_check_path + '/' + 'check1'\n","check_2_path = sanity_check_path + '/' + 'check2'\n","check_3_path = sanity_check_path + '/' + 'check3'\n","check_4_path = sanity_check_path + '/' + 'check4'\n","\n","if os.path.exists(sanity_check_path) == False:\n","  os.mkdir(sanity_check_path)\n","if os.path.exists(check_1_path) == False:\n","  os.mkdir(check_1_path)\n","if os.path.exists(check_2_path) == False:\n","  os.mkdir(check_2_path)\n","if os.path.exists(check_3_path) == False:\n","  os.mkdir(check_3_path)\n","if os.path.exists(check_4_path) == False:\n","  os.mkdir(check_4_path)"]},{"cell_type":"markdown","metadata":{"id":"a3ax56mR38tK"},"source":["### 6.2.1 Check 1\n","\n","For check 1 we first sample a user embedding, then determine its nearest neighbor in the **high-dimensional space** and finally we project all embeddings down to the lower dimensional space to visually inspect the proximity of the two observed embeddings.\n","\n","We perform this procedure for four embeddings at a time in order to avoid a coincidental observation of a high-quality proximity preservation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZK1kR_n4vFJ"},"outputs":[],"source":["color_iter = ['crimson','olive','cyan','gold']\n","nr_embeddings = data.shape[0]\n","idx = np.random.randint(nr_embeddings, size=4)\n","neighbors = np.empty((4,2))\n","\n","#iteration over different embedding pre-processings as they may impact the resulting proximity preservation\n","for pre_processing in ['none', 'feature_stand', 'norm_vecs']:\n","  if pre_processing == 'norm_vecs':\n","    scale_factors = np.sum(data, axis = 1)\n","    scale_factors = scale_factors[:, np.newaxis]\n","    processed_data = data / scale_factors\n","  elif pre_processing =='feature_stand':\n","    processed_data = StandardScaler().fit_transform(data)\n","  else:\n","    processed_data = data\n","\n","  #iteration over different distance metric as they may impact the resulting proximity preservation\n","  for measure in ['euclidean', 'cosine','manhattan']:\n","\n","    #sampling four user embeddings\n","    for i in range(4):\n","      sample_highdim = data[idx[i]]\n","      #determining the nearest neighbors of each embedding\n","      nn = NearestNeighbors(n_neighbors=2, metric = measure)\n","      nn.fit(data)\n","      sample_highdim = sample_highdim[np.newaxis,:]\n","      _ , neighbor = nn.kneighbors(sample_highdim)\n","      neighbors[i] = neighbor\n","    neighbors = np.asarray(neighbors, dtype = 'int')\n","\n","    #iteration over different number of neighbors and minimum distance parameter values as they may impact the resulting proximity preservation\n","    for n_neighbors in [2, 5,10,30]:\n","      for min_dist in [0.2, 0.4]:\n","\n","        #performing UMAP dimensionality reduction\n","        umap_reducer = umap.UMAP(n_components = 2, n_neighbors = n_neighbors, min_dist = min_dist, metric = measure) #initialize umap with desired hyperparams\n","        reduced_data = umap_reducer.fit_transform(processed_data) #calculate umap and return reduced embeddings\n","\n","        #setting up the plot\n","        plt.figure()\n","        plt.title(str(n_neighbors) +'   ' + str(min_dist) +'   ' + measure + '\\n' + pre_processing)\n","        plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=0.1, color = 'silver')\n","\n","        for i in range(4):\n","          neighbor_embeddings = reduced_data[neighbors[i],:]\n","          color = color_iter[i]\n","          plt.scatter(neighbor_embeddings[:, 0], neighbor_embeddings[:, 1], s=0.3, color = color)\n","\n","        plt.savefig(check_1_path + '/' + pre_processing + '_' + measure + '_' + str(n_neighbors) +'_' + str(min_dist) + '.pdf', bbox_inches='tight')"]},{"cell_type":"markdown","metadata":{"id":"eU5rbG566zib"},"source":["### 6.2.2 Check 2\n","\n","For check 2 we follow the same procedure as in check 1, with the only difference being that we determine the 20 nearest neighbors of each sampled user embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUwOTtEW60Oi"},"outputs":[],"source":["color_iter = ['crimson','olive','cyan','gold']\n","nr_embeddings = data.shape[0]\n","idx = np.random.randint(nr_embeddings, size=4)\n","neighbors = np.empty((4,20))\n","\n","#iteration over different embedding pre-processings as they may impact the resulting proximity preservation\n","for pre_processing in ['none', 'feature_stand', 'norm_vecs']:\n","  if pre_processing == 'norm_vecs':\n","    scale_factors = np.sum(data, axis = 1)\n","    scale_factors = scale_factors[:, np.newaxis]\n","    processed_data = data / scale_factors\n","  elif pre_processing =='feature_stand':\n","    processed_data = StandardScaler().fit_transform(data)\n","  else:\n","    processed_data = data\n","\n","  #iteration over different distance metric as they may impact the resulting proximity preservation\n","  for measure in ['euclidean', 'cosine','manhattan']:\n","\n","    #sampling four user embeddings\n","    for i in range(4):\n","      sample_highdim = data[idx[i]]\n","      #determining the nearest neighbors of each embedding\n","      nn = NearestNeighbors(n_neighbors=20, metric = measure)\n","      nn.fit(data)\n","      sample_highdim = sample_highdim[np.newaxis,:]\n","      _ , neighbor = nn.kneighbors(sample_highdim)\n","      neighbors[i] = neighbor\n","    neighbors = np.asarray(neighbors, dtype = 'int')\n","\n","    #iteration over different number of neighbors and minimum distance parameter values as they may impact the resulting proximity preservation\n","    for n_neighbors in [2, 5,10,30]:\n","      for min_dist in [0.2, 0.4]:\n","\n","        #performing UMAP dimensionality reduction\n","        umap_reducer = umap.UMAP(n_components = 2, n_neighbors = n_neighbors, min_dist = min_dist, metric = measure) #initialize umap with desired hyperparams\n","        reduced_data = umap_reducer.fit_transform(processed_data) #calculate umap and return reduced embeddings\n","\n","        #setting up the plot\n","        plt.figure()\n","        plt.title(str(n_neighbors) +'   ' + str(min_dist) +'   ' + measure + '\\n' + pre_processing)\n","        plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=0.1, color = 'silver')\n","\n","        for i in range(4):\n","          neighbor_embeddings = reduced_data[neighbors[i],:]\n","          color = color_iter[i]\n","          plt.scatter(neighbor_embeddings[:, 0], neighbor_embeddings[:, 1], s=0.3, color = color)\n","\n","        plt.savefig(check_2_path + '/' + '20points' + '_' + pre_processing + '_' + measure + '_' + str(n_neighbors) +'_' + str(min_dist) + '.pdf', bbox_inches='tight')"]},{"cell_type":"markdown","source":["###6.2.3 Check 3\n","\n","For check 3, we cluster the user embeddings in the high-dimensional space using K-Means, and then visualize the clusters in the lower-dimensional spcae."],"metadata":{"id":"bdcivz7A5net"}},{"cell_type":"code","source":["#Dimensionality reduction\n","reducer = umap.UMAP(n_components = 3, n_neighbors = 20, min_dist = 0.4, metric = 'cosine') #initialize umap with desired hyperparams\n","reduced_data = reducer.fit_transform(data)#calculate umap and return reduced embeddings\n","\n","#Clustering in the high-dimensioal space\n","kmeans = KMeans(init=\"random\", n_clusters=8, n_init=10, max_iter=300, random_state=42)\n","kmeans.fit(data)\n","labels = kmeans.labels_ #extracting labels of each sample\n","\n","#configuring plot settings, one color for each created label\n","plt.figure()\n","ax = plt.axes(projection='3d')\n","ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2],c = np.take(colors, labels),s=0.1)\n","path3D_image = check_3_path + '/' + '3d_20nn_0.4md_cosine'+ '.pdf'\n","plt.savefig(path3D_image, bbox_inches = 'tight')"],"metadata":{"id":"b8cWl9XD5kre","executionInfo":{"status":"ok","timestamp":1691948400135,"user_tz":-120,"elapsed":25771,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cj5DfEIbn4Q4"},"source":["### 6.2.4 Check 4\n","For check four, we randomly sample a user embedding and then determine the user embedding farthest away in the high-dimensional space. We then visualize both embeddings in the low-dimensional space.\n","\n","We perform this procedure for four embeddings at a time in order to avoid a coincidental observation of a high-quality proximity preservation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKYQ5InKoDZO"},"outputs":[],"source":["color_iter = ['crimson','olive','cyan','gold']\n","\n","#iteration over different embedding pre-processings as they may impact the resulting proximity preservation\n","for pre_processing in ['none', 'feature_stand', 'norm_vecs']:\n","  if pre_processing == 'norm_vecs':\n","    scale_factors = np.sum(data, axis = 1)\n","    scale_factors = scale_factors[:, np.newaxis]\n","    processed_data = data / scale_factors\n","  elif pre_processing =='feature_stand':\n","    processed_data = StandardScaler().fit_transform(data)\n","  else:\n","    processed_data = data\n","\n","  #iteration over different distance metric as they may impact the resulting proximity preservation\n","  for metric in ['euclidean', 'cosine', 'manhattan']:\n","    n_neighbors = 2\n","    min_dist = 0.4\n","    umap_reducer = umap.UMAP(n_components = 2, n_neighbors = n_neighbors, min_dist = min_dist, metric = metric) #initialize umap with desired hyperparams\n","    reduced_data = umap_reducer.fit_transform(processed_data) #calculate umap and return reduced embeddings\n","\n","    if metric == 'manhattan':\n","      metric_c = 'cityblock'\n","    else:\n","      metric_c = metric\n","\n","    distance_vec = pdist(data, metric = metric_c)\n","    distance_matrix = squareform(distance_vec)\n","\n","    #sampling four user embeddings\n","    for testpoints in range(4):\n","\n","      #determining user embeddings furthest away from sampled embedding in high-dimensional space\n","      max_distance, [i,j] = np.nanmax(distance_matrix), np.unravel_index( distance_matrix.argmax(), distance_matrix.shape )\n","      distance_matrix[i,j] = 0\n","      distance_matrix[j,i] = 0\n","      color = color_iter[testpoints]\n","\n","      #plot setup\n","      plt.figure()\n","      plt.title('Distant Points' + '\\n' + pre_processing + str(n_neighbors) +'   ' + str(min_dist) +'   ' + metric )\n","      plt.scatter(reduced_data[:, 0], reduced_data[:, 1], s=0.1, color = 'silver')\n","      plt.scatter(reduced_data[i, 0], reduced_data[i, 1], s=0.3, color = color)\n","      plt.scatter(reduced_data[j, 0], reduced_data[j, 1], s=0.3, color = color)\n","      print(np.linalg.norm(reduced_data[i] - reduced_data[j]) )\n","      print('manhattan' + str(distance.cityblock(reduced_data[i], reduced_data[j])))\n","      print('cosine'+ str(distance.cosine(reduced_data[i], reduced_data[j])))\n","      plt.savefig(check_4_path + '/' + pre_processing + '_' + metric + '_' + str(n_neighbors) +'_' + str(min_dist) + '.pdf', bbox_inches='tight')\n"]},{"cell_type":"markdown","metadata":{"id":"BpluG6GOSwaH"},"source":["# 7. Clustering\n","Finally, we will have to cluster the reduced dimensionality embeddings.\n","\n","In this section, we will try out different clustering algorithms with different hyperparameters each. We will furthermore use the CH-metric to support qualitative assesments of the clustering, enabling us to choose our final set of hyperparameters.\n","\n","Please note that this metric calculates the quality score of the clustering based on distance, i.e. factors such as cluster diameter, average distance between cluster points, distance between separate clusters etc..\n","Yet, as UMAP focuses on preserving the local structure of the data, the distances between clusters as well as the size of the clusters themselves are not interpretable. Moreover, some of the used clustering algorithms do not cluster according to distance but according to density, distribution, or graph structures. Therefore, the used metric does not perfectly evaluate the quality of the clustering and merely serves as an approximative assistance for the evalutation."]},{"cell_type":"markdown","metadata":{"id":"YZ2DgnBXeegT"},"source":["## 7.1 K-Means"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNuYSkX0Nt9D"},"outputs":[],"source":["#creating dict to track ch scores\n","ch_tracker = {}\n","print(iter_array)\n","\n","#iterating over the different hyperparameter values and reduced dimensionality embeddings\n","#we retrieve the embeddings from the embeddings dictionary created in section 4\n","for data_generation, pre_processing, dim_reduction, n_dims, n_neighbors, min_dist, measure in iter_array: #iteration over different reduced dim embeddings\n","  reduced_data = embeddings[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure]\n","\n","  #iterating over number of clusters\n","  for n_clusters in np.concatenate((range(5,10,1),range(10,41,5))):\n","\n","    #performing KMeans clustering\n","    kmeans = KMeans(init=\"random\", n_clusters=n_clusters, n_init=10, max_iter=300, random_state=42)\n","    kmeans.fit(reduced_data)\n","    labels = kmeans.labels_ #extracting labels of each sample\n","    ch_score = round(metrics.calinski_harabasz_score(reduced_data, labels),2)\n","    ch_tracker[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure + str(n_clusters)] = ch_score\n","\n","    #2-dimensional case\n","    if n_dims == '2':\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      plt.scatter(reduced_data[:,0], reduced_data[:,1], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score) + '    nr clusters:' + str(n_clusters) + '   Kmeans', fontsize=8)\n","      clustering_path = w_path  + data_generation + '/' + 'k_means' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path  + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(n_clusters) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')\n","\n","    #3-dimensional case\n","    else:\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score)+ '    nr clusters:' + str(n_clusters) + '   Kmeans', fontsize=8)\n","      clustering_path = w_path  + data_generation + '/' + 'k_means' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(n_clusters) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1688562066174,"user":{"displayName":"Mara K.","userId":"07948848994085884880"},"user_tz":-120},"id":"KJPGmUMspVWn","outputId":"cc62f640-2e40-4ef6-ab7f-161e8409bcf0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             values\n","finalnoneUMAP220.4cosine40  3888.60\n","finalnoneUMAP220.4cosine35  3580.45\n","finalnoneUMAP220.4cosine30  3065.67\n","finalnoneUMAP220.4cosine25  3025.41\n","finalnoneUMAP220.4cosine20  3005.62"],"text/html":["\n","  <div id=\"df-fb9653f1-c259-40f3-91b0-6945f0638999\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine40</th>\n","      <td>3888.60</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine35</th>\n","      <td>3580.45</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine30</th>\n","      <td>3065.67</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine25</th>\n","      <td>3025.41</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine20</th>\n","      <td>3005.62</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb9653f1-c259-40f3-91b0-6945f0638999')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fb9653f1-c259-40f3-91b0-6945f0638999 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fb9653f1-c259-40f3-91b0-6945f0638999');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["#Determining the best clusters according to ch score and printing them in table\n","largest_keys = sorted(ch_tracker, key=ch_tracker.get, reverse=True)[:5]\n","largest_vals = [ch_tracker[x] for x in largest_keys]\n","length = len(largest_vals)\n","heading = np.empty(length, dtype = str)\n","heading[:] = 'value'\n","pd.DataFrame(largest_vals, index = largest_keys, columns=[\"values\"])"]},{"cell_type":"markdown","metadata":{"id":"aTreXmaj_83i"},"source":["## 7.2 Agglomerative Clustering\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPEY6grJd6BQ"},"outputs":[],"source":["#creating dict to track ch scores\n","ch_tracker = {}\n","\n","#iterating over the different hyperparameter values and reduced dimensionality embeddings\n","#we retrieve the embeddings from the embeddings dictionary created in section 4\n","for data_generation, pre_processing, dim_reduction, n_dims, n_neighbors, min_dist, measure in iter_array: #iteration over different reduced dim embeddings\n","  reduced_data = embeddings[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure]\n","\n","  #iterating over number of clusters\n","  for n_clusters in np.concatenate((range(5,10,1),range(10,41,5))):\n","    agglo = AgglomerativeClustering(n_clusters = n_clusters)\n","    agglo.fit(reduced_data)\n","    labels =  agglo.labels_\n","    ch_score = round(metrics.calinski_harabasz_score(reduced_data, labels),2)\n","    ch_tracker[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure + str(n_clusters)] = ch_score\n","\n","    #2-dimensional case\n","    if n_dims == '2':\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      plt.scatter(reduced_data[:,0], reduced_data[:,1], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score) + '    nr clusters:' + str(n_clusters) + '\\n Agglo', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'agglo' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(n_clusters) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')\n","\n","    #3-dimensional case\n","    else:\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score)+ '    nr clusters:' + str(n_clusters)+ '\\n Agglo', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'agglo' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(n_clusters) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1688562706138,"user":{"displayName":"Mara K.","userId":"07948848994085884880"},"user_tz":-120},"id":"1t9-0Qq6Myq9","outputId":"96f97536-5d57-4fec-d86b-62607ad2384e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             values\n","finalnoneUMAP220.4cosine40  4851.26\n","finalnoneUMAP220.4cosine35  4248.93\n","finalnoneUMAP220.4cosine30  3796.42\n","finalnoneUMAP220.4cosine25  3475.18\n","finalnoneUMAP320.4cosine40  3363.84"],"text/html":["\n","  <div id=\"df-b3242a4c-1b61-425d-9a86-13dd03c14805\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine40</th>\n","      <td>4851.26</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine35</th>\n","      <td>4248.93</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine30</th>\n","      <td>3796.42</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine25</th>\n","      <td>3475.18</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP320.4cosine40</th>\n","      <td>3363.84</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3242a4c-1b61-425d-9a86-13dd03c14805')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b3242a4c-1b61-425d-9a86-13dd03c14805 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b3242a4c-1b61-425d-9a86-13dd03c14805');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}],"source":["#Determining the best clusters according to ch score and printing them in table\n","largest_keys = sorted(ch_tracker, key=ch_tracker.get, reverse=True)[:5]\n","largest_vals = [ch_tracker[x] for x in largest_keys]\n","length = len(largest_vals)\n","heading = np.empty(length, dtype = str)\n","heading[:] = 'value'\n","pd.DataFrame(largest_vals, index = largest_keys, columns=[\"values\"])"]},{"cell_type":"markdown","metadata":{"id":"EGAtNW3XALKE"},"source":["## 7.3 Spectral Clustering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ge56iOjriWpP"},"outputs":[],"source":["#creating dict to track ch scores\n","ch_tracker = {}\n","\n","#iterating over the different hyperparameter values and reduced dimensionality embeddings\n","#we retrieve the embeddings from the embeddings dictionary created in section 4\n","for data_generation, pre_processing, dim_reduction, n_dims, n_neighbors, min_dist, measure in iter_array: #iteration over different reduced dim embeddings\n","  reduced_data = embeddings[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure]\n","\n","  #iterating over different number of clusters\n","  for n_clusters in np.concatenate((range(5,10,1),range(10,41,5))):\n","    spectral = SpectralClustering(n_clusters = n_clusters)\n","    spectral.fit(reduced_data)\n","    labels =  spectral.labels_\n","    ch_score = round(metrics.calinski_harabasz_score(reduced_data, labels),2)\n","    ch_tracker[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure + str(n_clusters)] = ch_score\n","\n","    #2-dimensional case\n","    if n_dims == '2':\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      plt.scatter(reduced_data[:,0], reduced_data[:,1], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score) + '    nr clusters:' + str(n_clusters)+ '\\n Spectral', fontsize=8)\n","      clustering_path = w_path  + data_generation + '/' + 'spectral' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(n_clusters) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')\n","\n","    #3-dimensional case\n","    else:\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score)+ '    nr clusters:' + str(n_clusters)+ '\\n Spectral', fontsize=8)\n","      clustering_path = w_path  + data_generation + '/' + 'spectral' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(n_clusters) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-LQzE7wKN4mx","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1688569027580,"user_tz":-120,"elapsed":0,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}},"outputId":"5eea9015-37f1-4038-b3c3-2a3d8da83d49"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-5dae20e9-e173-4527-a146-6860c956e9d4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine40</th>\n","      <td>4114.15</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine35</th>\n","      <td>3588.90</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP320.4cosine40</th>\n","      <td>3120.19</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine30</th>\n","      <td>3034.22</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP320.4cosine35</th>\n","      <td>2853.73</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dae20e9-e173-4527-a146-6860c956e9d4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5dae20e9-e173-4527-a146-6860c956e9d4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5dae20e9-e173-4527-a146-6860c956e9d4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                             values\n","finalnoneUMAP220.4cosine40  4114.15\n","finalnoneUMAP220.4cosine35  3588.90\n","finalnoneUMAP320.4cosine40  3120.19\n","finalnoneUMAP220.4cosine30  3034.22\n","finalnoneUMAP320.4cosine35  2853.73"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["#Determining the best clusters according to ch score and printing them in table\n","largest_keys = sorted(ch_tracker, key=ch_tracker.get, reverse=True)[:5]\n","largest_vals = [ch_tracker[x] for x in largest_keys]\n","length = len(largest_vals)\n","heading = np.empty(length, dtype = str)\n","heading[:] = 'value'\n","pd.DataFrame(largest_vals, index = largest_keys, columns=[\"values\"])"]},{"cell_type":"markdown","metadata":{"id":"rHA7GrJiAWs6"},"source":["## 7.4 BIRCH Clustering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Te7TimFYyA6N"},"outputs":[],"source":["#creating dict to track ch scores\n","ch_tracker = {}\n","\n","#iterating over the different hyperparameter values and reduced dimensionality embeddings\n","#we retrieve the embeddings from the embeddings dictionary created in section 4\n","for data_generation, pre_processing, dim_reduction, n_dims, n_neighbors, min_dist, measure in iter_array: #iteration over different reduced dim embeddings\n","  reduced_data = embeddings[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure]\n","\n","  #iterating over number of clusters\n","  for n_clusters in np.concatenate((range(5,10,1),range(10,41,5))):\n","    birch = Birch(n_clusters = n_clusters)\n","    birch.fit(reduced_data)\n","    labels =  birch.labels_\n","    ch_score = round(metrics.calinski_harabasz_score(reduced_data, labels))\n","    ch_tracker[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure + str(n_clusters)] = ch_score\n","\n","    #2-dimensional case\n","    if n_dims == '2':\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      plt.scatter(reduced_data[:,0], reduced_data[:,1], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score) + '    nr clusters:' + str(n_clusters) + '\\n BIRCH', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'BIRCH' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(n_clusters) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')\n","\n","    #3-dimensional case\n","    else:\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score)+ '    nr clusters:' + str(n_clusters) + '\\n Birch', fontsize=8)\n","      clustering_path = w_path  + data_generation + '/' + 'BIRCH' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(n_clusters) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43WtpLVuBoY2"},"outputs":[],"source":["#Determining the best clusters according to ch score and printing them in table\n","largest_keys = sorted(ch_tracker, key=ch_tracker.get, reverse=True)[:5]\n","largest_vals = [ch_tracker[x] for x in largest_keys]\n","length = len(largest_vals)\n","heading = np.empty(length, dtype = str)\n","heading[:] = 'value'\n","pd.DataFrame(largest_vals, index = largest_keys, columns=[\"values\"])"]},{"cell_type":"markdown","metadata":{"id":"H87toLxrAbax"},"source":["## 7.5 Optics Clustering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZNfdQ3L0-ib"},"outputs":[],"source":["#creating dict to track ch scores\n","ch_tracker = {}\n","\n","#iterating over the different hyperparameter values and reduced dimensionality embeddings\n","#we retrieve the embeddings from the embeddings dictionary created in section 4\n","for data_generation, pre_processing, dim_reduction, n_dims, n_neighbors, min_dist, measure in iter_array: #iteration over different reduced dim embeddings\n","  reduced_data = embeddings[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure]\n","\n","  #iterating over number of samples in a neighborhood for a point to be considered as a core point\n","  for min_samples in range(20,100,5):\n","    optics = OPTICS(min_samples = min_samples)\n","    optics.fit(reduced_data)\n","    labels = optics.labels_\n","    ch_score = round(metrics.calinski_harabasz_score(reduced_data, labels))\n","    ch_tracker[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure + str(n_clusters)] = ch_score\n","\n","    #2-dimensional case\n","    if n_dims == '2':\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      plt.scatter(reduced_data[:,0], reduced_data[:,1], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '   -  ' + pre_processing + '  -   ' + dim_reduction + ' \\n ' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + ' \\n ch score:'+ str(ch_score) + '    min samples:' + str(min_samples) +  ' \\n Optics', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'Optics' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(min_samples) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')\n","\n","    #3-dimensional case\n","    else:\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + ' \\n ch score:' + str(ch_score)+ '    min samples:' + str(min_samples) + '\\n Optics', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'Optics' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(min_samples) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1688569144601,"user":{"displayName":"Mara K.","userId":"07948848994085884880"},"user_tz":-120},"id":"eexmvBKZBsI-","outputId":"26b5a356-5963-476d-d69e-b00a1047ec77"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            values\n","finalnoneUMAP320.4cosine40     675\n","finalnoneUMAP220.4cosine40     314"],"text/html":["\n","  <div id=\"df-2e6527bc-8e50-470a-98e9-3258b7d5d3af\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>finalnoneUMAP320.4cosine40</th>\n","      <td>675</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine40</th>\n","      <td>314</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e6527bc-8e50-470a-98e9-3258b7d5d3af')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2e6527bc-8e50-470a-98e9-3258b7d5d3af button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2e6527bc-8e50-470a-98e9-3258b7d5d3af');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}],"source":["#Determining the best clusters according to ch score and printing them in table\n","largest_keys = sorted(ch_tracker, key=ch_tracker.get, reverse=True)[:5]\n","largest_vals = [ch_tracker[x] for x in largest_keys]\n","length = len(largest_vals)\n","heading = np.empty(length, dtype = str)\n","heading[:] = 'value'\n","pd.DataFrame(largest_vals, index = largest_keys, columns=[\"values\"])"]},{"cell_type":"markdown","metadata":{"id":"VpEzuYw4AkaM"},"source":["## 7.6 DBScan Clustering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csrtURut9Ji-"},"outputs":[],"source":["#creating dict to track ch scores\n","ch_tracker = {}\n","\n","#iterating over the different hyperparameter values and reduced dimensionality embeddings\n","for data_generation, pre_processing, dim_reduction, n_dims, n_neighbors, min_dist, measure in iter_array: #iteration over different reduced dim embeddings\n","  reduced_data = embeddings[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure]\n","\n","  #iterating over number of samples in a neighborhood for a point to be considered as a core point\n","  for min_samples in range(1,200,5):\n","    for eps in range(1, 100, 1):\n","      dbscan = DBSCAN(eps= eps/2, min_samples = min_samples)\n","      dbscan.fit(reduced_data)\n","      labels = dbscan.labels_\n","    if len(np.unique(labels)) > 1:\n","      ch_score = round(metrics.calinski_harabasz_score(reduced_data, labels),2)\n","    else:\n","      ch_score = 0\n","    ch_tracker[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure + str(min_samples) + str(eps)] = ch_score\n","\n","    #2-dimensional case\n","    if n_dims == '2':\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      plt.scatter(reduced_data[:,0], reduced_data[:,1], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score) + '    min samples:' + str(min_samples) + '    eps:'+ str(eps) + '\\n DBScan', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'DBScan' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(min_samples) + '_' + str(eps) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')\n","\n","    #3-dimensional case\n","    else:\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score)+ '    min samples:' + str(min_samples)+ '    eps:'+ str(eps) +'\\n DBScan', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'DBScan' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(min_samples) + '_' + str(eps) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDY3KVGLBt9Y","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1688578090970,"user_tz":-120,"elapsed":561,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}},"outputId":"b76f2dd3-d969-4ec0-9436-009fb3a20829"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              values\n","finalnoneUMAP220.4cosine199        0\n","finalnoneUMAP220.4cosine699        0\n","finalnoneUMAP220.4cosine1199       0\n","finalnoneUMAP220.4cosine1699       0\n","finalnoneUMAP220.4cosine2199       0"],"text/html":["\n","  <div id=\"df-bb537f0a-8cc4-4e52-b161-4b4d01ac9a08\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine199</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine699</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine1199</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine1699</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine2199</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb537f0a-8cc4-4e52-b161-4b4d01ac9a08')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bb537f0a-8cc4-4e52-b161-4b4d01ac9a08 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bb537f0a-8cc4-4e52-b161-4b4d01ac9a08');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}],"source":["#Determining the best clusters according to ch score and printing them in table\n","largest_keys = sorted(ch_tracker, key=ch_tracker.get, reverse=True)[:5]\n","largest_vals = [ch_tracker[x] for x in largest_keys]\n","length = len(largest_vals)\n","heading = np.empty(length, dtype = str)\n","heading[:] = 'value'\n","pd.DataFrame(largest_vals, index = largest_keys, columns=[\"values\"])"]},{"cell_type":"markdown","metadata":{"id":"jK7wGdw6OLPw"},"source":["## 7.6 Gaussian Mixture Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8qexMdvvOKbs"},"outputs":[],"source":["#creating dict to track ch scores\n","ch_tracker = {}\n","\n","#iterating over the different hyperparameter values and reduced dimensionality embeddings\n","#we retrieve the embeddings from the embeddings dictionary created in section 4\n","for data_generation, pre_processing, dim_reduction, n_dims, n_neighbors, min_dist, measure in iter_array: #iteration over different reduced dim embeddings\n","  reduced_data = embeddings[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure]\n","\n","  #iterating over number of clusters\n","  for nr_components in np.concatenate((range(5,10,1),range(10,41,5))):\n","    gmm = mixture.GaussianMixture(n_components=nr_components)\n","    labels = gmm.fit_predict(reduced_data)\n","    ch_score = round(metrics.calinski_harabasz_score(reduced_data, labels),2)\n","    ch_tracker[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure + str(nr_components)] = ch_score\n","\n","    #2-dimensional case\n","    if n_dims == '2':\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      plt.scatter(reduced_data[:,0], reduced_data[:,1], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score) + '    nr components:' + str(nr_components) + '\\n GMM', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'GMM' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(nr_components) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')\n","\n","    #3-dimensional case\n","    else:\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score)+ '    nr components:' + str(nr_components)+ '\\n DBScan', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'GMM' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path  + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(nr_components) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HXZ0lDYwPyWn","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1688577360786,"user_tz":-120,"elapsed":10,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}},"outputId":"672c53a5-76c8-4835-8748-ce1216a12694"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             values\n","finalnoneUMAP220.4cosine40  4082.12\n","finalnoneUMAP220.4cosine35  3541.39\n","finalnoneUMAP220.4cosine30  3396.23\n","finalnoneUMAP220.4cosine25  3142.05\n","finalnoneUMAP320.4cosine40  3119.29"],"text/html":["\n","  <div id=\"df-da945887-b0ad-4cf1-bd2f-53c285a9fe34\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine40</th>\n","      <td>4082.12</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine35</th>\n","      <td>3541.39</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine30</th>\n","      <td>3396.23</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine25</th>\n","      <td>3142.05</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP320.4cosine40</th>\n","      <td>3119.29</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da945887-b0ad-4cf1-bd2f-53c285a9fe34')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-da945887-b0ad-4cf1-bd2f-53c285a9fe34 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-da945887-b0ad-4cf1-bd2f-53c285a9fe34');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}],"source":["#Determining the best clusters according to ch score and printing them in table\n","largest_keys = sorted(ch_tracker, key=ch_tracker.get, reverse=True)[:5]\n","largest_vals = [ch_tracker[x] for x in largest_keys]\n","length = len(largest_vals)\n","heading = np.empty(length, dtype = str)\n","heading[:] = 'value'\n","pd.DataFrame(largest_vals, index = largest_keys, columns=[\"values\"])"]},{"cell_type":"markdown","metadata":{"id":"zB1vN5JxPq4S"},"source":["##7.7 Bayesian Gaussian Mixture Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGZWBcgBPwY0"},"outputs":[],"source":["#creating dict to track ch scores\n","ch_tracker = {}\n","\n","#iterating over the different hyperparameter values and reduced dimensionality embeddings\n","#we retrieve the embeddings from the embeddings dictionary created in section 4\n","for data_generation, pre_processing, dim_reduction, n_dims, n_neighbors, min_dist, measure in iter_array: #iteration over different reduced dim embeddings\n","  reduced_data = embeddings[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure]\n","\n","  #iterating over number of clusters\n","  for nr_components in np.concatenate((range(5,10,1),range(10,41,5))):\n","    vgmm = BayesianGaussianMixture(n_components=nr_components, random_state=42)\n","    labels = vgmm.fit_predict(reduced_data)\n","    ch_score = round(metrics.calinski_harabasz_score(reduced_data, labels),2)\n","    ch_tracker[data_generation + pre_processing + dim_reduction + n_dims + n_neighbors+ min_dist + measure + str(nr_components)] = ch_score\n","\n","    #2-dimensional case\n","    if n_dims == '2':\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      plt.scatter(reduced_data[:,0], reduced_data[:,1], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score) + '    nr components:' + str(nr_components) + '\\n B_GMM', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'B_GMM' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(nr_components) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')\n","\n","    #3-dimensional case\n","    else:\n","\n","      #configuring plot settings, one color for each created label\n","      plt.figure()\n","      ax = plt.axes(projection='3d')\n","      ax.scatter3D(reduced_data[:, 0], reduced_data[:, 1], reduced_data[:, 2], c = np.take(colors, labels), s=0.1)\n","      plt.title(data_generation + '     ' + pre_processing + '     ' + dim_reduction + '\\n' + 'n_neighbors:' + n_neighbors+ '     min_dist:' + min_dist + '     metric:' + measure + '\\n' + 'ch score:'+str(ch_score)+ '    nr components:' + str(nr_components)+ '\\n B_GMM', fontsize=8)\n","      clustering_path = w_path + data_generation + '/' + 'B_GMM' + '/' + pre_processing\n","      if os.path.exists(clustering_path) == False:\n","        os.mkdir(clustering_path)\n","      clustering_path = clustering_path + '/' + n_dims + '_' + n_neighbors + '_' + min_dist + '_' + measure + '_'+ str(nr_components) +'.pdf'\n","      plt.savefig(clustering_path , bbox_inches='tight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7fG1f2wPzUX","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1688577414069,"user_tz":-120,"elapsed":42,"user":{"displayName":"Mara K.","userId":"07948848994085884880"}},"outputId":"6bf7baa0-12dd-4ca5-fc06-5c9a1f902b3b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             values\n","finalnoneUMAP320.4cosine30  2555.06\n","finalnoneUMAP220.4cosine15  2510.10\n","finalnoneUMAP320.4cosine40  2479.25\n","finalnoneUMAP320.4cosine35  2416.49\n","finalnoneUMAP220.4cosine25  2405.24"],"text/html":["\n","  <div id=\"df-a8823bf5-d40e-493c-a32b-d48c3db1a071\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>values</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>finalnoneUMAP320.4cosine30</th>\n","      <td>2555.06</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine15</th>\n","      <td>2510.10</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP320.4cosine40</th>\n","      <td>2479.25</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP320.4cosine35</th>\n","      <td>2416.49</td>\n","    </tr>\n","    <tr>\n","      <th>finalnoneUMAP220.4cosine25</th>\n","      <td>2405.24</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8823bf5-d40e-493c-a32b-d48c3db1a071')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a8823bf5-d40e-493c-a32b-d48c3db1a071 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a8823bf5-d40e-493c-a32b-d48c3db1a071');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":30}],"source":["#Determining the best clusters according to ch score and printing them in table\n","largest_keys = sorted(ch_tracker, key=ch_tracker.get, reverse=True)[:5]\n","largest_vals = [ch_tracker[x] for x in largest_keys]\n","length = len(largest_vals)\n","heading = np.empty(length, dtype = str)\n","heading[:] = 'value'\n","pd.DataFrame(largest_vals, index = largest_keys, columns=[\"values\"])"]}],"metadata":{"colab":{"collapsed_sections":["92wlMVhTK-I7","Hl1ZDb53R0S-","oz6p3uN3MSTw","a3ax56mR38tK","eU5rbG566zib","cj5DfEIbn4Q4"],"provenance":[{"file_id":"1mMhCobnsNbDyLjE1Zmv-whTp_MOI-31d","timestamp":1691947191798},{"file_id":"1lSV14KTzrfA6wCIeDqKF2bAJUQC74m1y","timestamp":1686479819901},{"file_id":"1k3q_zUfE0pDlSYyBu2ywFTcoWn60nP8_","timestamp":1685368241523}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}